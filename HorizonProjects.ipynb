{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c25c73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14479474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get projects data\n",
    "df_project = pd.read_excel(\"data/project.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eeacd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_project.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8dc49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add classification identifiers\n",
    "df_euro = pd.read_excel(\"data/euroSciVoc.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34eb7d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_euro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fe5848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# change id name for merging\n",
    "df_euro[\"id\"] = df_euro[\"projectID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d372a863",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge the two\n",
    "result = pd.merge(df_project, df_euro, on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc143c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1573ee9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look only at MSCA PF\n",
    "df = result[result['topics'].str.contains(\"MSCA\") & result['topics'].str.contains(\"PF\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad53024",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['euroSciVocPath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef8280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's extract the main topic\n",
    "df['mainTopic'] = df['euroSciVocPath'].str.split('/').apply(lambda x: x[1] if len(x) > 1 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a674b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's look at the main topics\n",
    "df['mainTopic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef90062b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# economics\n",
    "df[df['euroSciVocPath'].str.contains(\"economics\")]['euroSciVocPath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95695c94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#physics\n",
    "df[df['euroSciVocPath'].str.contains(\"physical sciences\")]['euroSciVocPath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcafffc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chemistry\n",
    "df[df['euroSciVocPath'].str.contains(\"chemical sciences\")]['euroSciVocPath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f074f789",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# engineering\n",
    "df[df['euroSciVocPath'].str.contains(\"engineering and technology\")]['euroSciVocPath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87440382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# environmental and geosciences\n",
    "df[df['euroSciVocPath'].str.contains(\"environment\")]['euroSciVocPath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbcb53a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# life sciences\n",
    "df[df['euroSciVocPath'].str.contains(\"medical and health\")]['euroSciVocPath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c7528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# math\n",
    "df[df['euroSciVocPath'].str.contains(\"math\")]['euroSciVocPath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99974646",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# social sciences\n",
    "df[~df['euroSciVocPath'].str.contains(\"economics\") & df['euroSciVocPath'].str.contains(\"social sciences\")]['euroSciVocPath']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f509ac9f",
   "metadata": {},
   "source": [
    "### Only for social sciences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad4885",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soc = df[~df['euroSciVocPath'].str.contains(\"economics\") & df['euroSciVocPath'].str.contains(\"social sciences\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aea96a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71b37f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soc[soc['euroSciVocPath'].str.contains(\"sociology\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b06ce1b",
   "metadata": {},
   "source": [
    "### Topic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d95e63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "print(spacy.__version__)\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "import os,sys\n",
    "import math\n",
    "import csv\n",
    "\n",
    "## custom packages\n",
    "src_dir = os.path.join( 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from filter_words import run_stopword_statistics\n",
    "from filter_words import make_stopwords_filter\n",
    "from filter_words import remove_stopwords_from_list_texts\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "from helper_functions import clean_stopwords, coherence_per_topic, find_best_n_topics, get_clean_output, get_list, get_top_n_words, get_topics_from_model, has_numbers, my_lemmatizer, plot_top_words, plot_top_words_colors, process_words\n",
    "\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import re\n",
    "\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.model_selection  import GridSearchCV\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from joblib import dump, load\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae44ebc3",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d445b715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## creating set of stopwords using Sarica and Luo 2021 paper\n",
    "path_stopword_list =  os.path.join('data','sarica_and_luo_2021.txt')\n",
    "if path_stopword_list != None:\n",
    "    with open(path_stopword_list,'r', encoding='utf-8') as f:\n",
    "        x = f.readlines()\n",
    "    stopwords = set([word.lower() for h in x for word in h.strip().split(' ')])\n",
    "    \n",
    "## remove all acronyms\n",
    "stopwords = stopwords.union(set(df['acronym']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab588b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts = list(soc['objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aebe220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(texts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919d5cf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\" in texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040b611",
   "metadata": {},
   "source": [
    "## Clean stopwords and uninformative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541fb6a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst = get_list(texts = texts, stop_words = stopwords, processing_choice='nouns', N_s=100, cutoff_val=0.5, path_to_file = 'data/obj_')\n",
    "output = get_clean_output(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04561d58",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769b3882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scorer_sklearn(estimator, X,y=None):\n",
    "    \n",
    "    topics = get_topics_from_model(\n",
    "        estimator,\n",
    "        vectorizer,\n",
    "        n_top_words\n",
    "    )\n",
    "    cm = CoherenceModel(\n",
    "        topics=topics,\n",
    "        texts = output['list_texts_filter'],\n",
    "        corpus=output['corpus_filter'], \n",
    "        dictionary=output['dictionary_filter'],  \n",
    "        coherence='c_v', \n",
    "        topn=n_top_words,\n",
    "        processes=1\n",
    "    )\n",
    "\n",
    "    return cm.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe11017a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts_nouns = output['texts_filter']\n",
    "\n",
    "n_samples = len(texts_nouns)\n",
    "n_features = output['n_features'] # from above at corpus\n",
    "n_components = 50\n",
    "n_top_words = 20\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    #max_features=n_features, stop_words=list(stopwords)\n",
    ")\n",
    "\n",
    "tfidf = vectorizer.fit_transform(texts_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653a615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317b5932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = NMF(\n",
    "    n_components=n_components,\n",
    "    random_state=82,\n",
    "    beta_loss=\"kullback-leibler\",\n",
    "    init=\"nndsvda\",\n",
    "    solver=\"mu\",\n",
    "    max_iter=200,\n",
    "    alpha_W=0.01,\n",
    "    l1_ratio=0.2,\n",
    ").fit(tfidf)\n",
    "\n",
    "scorer_sklearn(model, texts_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb0869c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf_feature_names = vectorizer.get_feature_names_out()\n",
    "plot_top_words(model, tf_feature_names, n_top_words, \"title\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1111817",
   "metadata": {},
   "source": [
    "## Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b991e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pyLDAvis\n",
    "\n",
    "import pyLDAvis.lda_model\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "viz = pyLDAvis.lda_model.prepare(model, tfidf, vectorizer)\n",
    "viz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f2c0b3",
   "metadata": {},
   "source": [
    "### Physics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264d122",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "phys = df[df['euroSciVocPath'].str.contains(\"physical sciences\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53169e8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "texts = list(phys['objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66287673",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902aa452",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lst = get_list(texts = texts, stop_words = stopwords, processing_choice='nouns', N_s=100, cutoff_val=0.5, path_to_file = 'data/phys_')\n",
    "output = get_clean_output(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52498db0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "texts_nouns = output['texts_filter']\n",
    "\n",
    "n_samples = len(texts_nouns)\n",
    "n_features = output['n_features'] # from above at corpus\n",
    "n_components = 50\n",
    "n_top_words = 20\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    #max_features=n_features, stop_words=list(stopwords)\n",
    ")\n",
    "\n",
    "tfidf = vectorizer.fit_transform(texts_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac20159",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = NMF(\n",
    "    n_components=n_components,\n",
    "    random_state=82,\n",
    "    beta_loss=\"kullback-leibler\",\n",
    "    init=\"nndsvda\",\n",
    "    solver=\"mu\",\n",
    "    max_iter=200,\n",
    "    alpha_W=0.01,\n",
    "    l1_ratio=0.2,\n",
    ").fit(tfidf)\n",
    "\n",
    "scorer_sklearn(model, texts_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f7cc45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf_feature_names = vectorizer.get_feature_names_out()\n",
    "plot_top_words(model, tf_feature_names, n_top_words, \"title\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad8e44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pyLDAvis\n",
    "\n",
    "import pyLDAvis.lda_model\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "viz = pyLDAvis.lda_model.prepare(model, tfidf, vectorizer)\n",
    "viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7501d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
